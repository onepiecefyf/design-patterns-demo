# 中间件一键部署工具

[TOC]

## 前言

一键部署技术实现：ansible + golang

可以在提供的中间件中选择需要的部署

安装工具使用用户：`root`

目标机使用用户：`root`

网络环境要先打通。目标机都可达，需要的端口都要开通，如mysql的3306、redis的6379、kafka的9092、nginx的80等。测试是在关闭防火墙，网络全通的情况下验证的。

保证提供的目标机都是可用的。先要进行一些基础的检查，比如：系统时间都要正确，网卡是类似eth0还是enp0s3，高可用的VIP要挂载在哪个网卡上。

支持操作系统：Centos [6.5 - 7.5] Redhat6.5 Redhat7.0

测试验证的系统：

| 系统 | 版本 |
|------| ----|
|CentOS | 6.5|
|CentOS | 6.8|
|CentOS | 7.0|
|CentOS | 7.1|
|CentOS | 7.5|
|RedHat | 6.5|
|RedHat | 7.0|
|SUSE12sp4 |12sp4 <br>只支持redis单机和高可用|

支持中间件列表：

| 中间件     | 版本                                                      |
| ---------- | --------------------------------------------------------- |
| MySQL      | mysql-5.7.35-linux-glibc2.12                              |
| Java       | jdk-8u191-linux-x64.tar.gz<br />jdk-7u80-linux-x64.tar.gz |
| Nginx      | centos7: nginx-1.20.1-1 <br />centos6: nginx-1.18.2-1     |
| Redis      | redis-4.0.14                                              |
| zookeeper  | zookeeper-3.4.14                                          |
| Kafka      | kafka_2.11-0.10.0.0                                       |
| Tomcat     | tomcat-8.5.41                                             |
| Keepalived | keepalived-1.3.5.el7<br />keepalived-1.2.7.el6            |
| Elasticsearch | elasticsearch-6.8.5 |

## 环境准备

确保目标机器上，没有要安装的中间件，如有，请先自行删除。

如：目标机系统自带了ansible，要先删除，再安装提供的版本。

### 安装一键部署软件
- 获取安装包

请联系 生产及售后管理部（姚傲林 yaoaolin@bjca.org.cn）出库 中间件一键部署工具，会拿到安装包ansible-roles.zip

将文件上传到目标主机 `/opt/soft`目录上，目录无限制，推荐`/opt/soft`，解压ansible-roles.zip，进入ansible-roles目录（文档中提到的文件均在ansible-roles目录下）

- 安装ansible

```bash
# 给aci赋可执行权限
chmod +x aci
# 安装ansible
./aci ansible install
```

- 设置ansible配置文件
```bash
mkdir -p /etc/ansible && cp ansible.cfg /etc/ansible/
```

- 检查ansible是否安装成功

```bash
ansible --version
```

显示结果类似如下，版本号`ansible 2.6.17`

```bash
[root@app01 ansible-system-rpms.el6]# ansible --version
ansible 2.6.17
  config file = /etc/ansible/ansible.cfg
  configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python2.6/site-packages/ansible
  executable location = /usr/bin/ansible
  python version = 2.6.6 (r266:84292, Nov 22 2013, 12:16:22) [GCC 4.4.7 20120313 (Red Hat 4.4.7-4)]
```

### 一键部署总体流程
- 首先保证ansible安装成功
- inventory 文件里配置要部署中间件的目标机器，指定目标机名称、IP、用户名(必须用root)、密码
  ansible会使用配置的信息登录目标机，安装程序
  示例：
```ini
[nginx]
192.168.33.110
[mysql]
192.168.33.111
[redis]
192.168.33.112
[kafka]
192.168.33.113

[all:vars]
ansible_ssh_user=root
ansible_ssh_pass=vagrant
```
- xxx.yml（如：kafka.yml nginx.yml） 配置要在目标机上安装的中间件
  hosts 指定目标机名称，和inventory配置对应，请按需修改
  vars 指定中间件的配置参数，如mysql的端口，请按需修改
  roles 指定要安装的中间件，如mysql，不用动
  示例：
```yml
---
#### 安装mysql
- hosts: mysql
  remote_user: root
  vars:
    - mysql57_user: "root"
    - mysql57_password: "1qazzaq1"
    - mysql57_port: 3306
  roles:
    - { role: mysql }
```
- 执行安装命令，就可以安装中间件到目标机上了
  如：ansible-playbook -i inventory xxx.yml



- 部署示意图

```bash

                                      +-----------------+
                                      | nginx           |
                                      | 192.168.33.110  |
                                      | root            |
                                      +-----------------+

                                      +-----------------+
                                      | mysql           |
                                      | 192.168.33.111  |
                                      | root            |
      +---------+                     +-----------------+
      | ansible +----------------->
      +---------+                     +-----------------+
                                      | redis           |
                                      | 192.168.33.112  |
                                      | root            |
                                      +-----------------+

                                      +-----------------+
                                      | kafka           |
                                      | 192.168.33.113  |
                                      | root            |
                                      +-----------------+

```

## 所有主机需要执行初始配置任务
作用是统一设置一些系统参数，例如设置文件打开数量
编辑 init.yml 文件，指定hosts即可，其他不用动
```yml
- hosts: mysql1,mysql2  #需要执行初始化的主机
  remote_user: root
  vars:
    - local_ip: "{{ ansible_default_ipv4.address }}"
    - domain_conf:
        kafka: "{{ local_ip }}"
        redis: "{{ local_ip }}"
        zookeeper: "{{ local_ip }}"
        jdbc: "{{ local_ip }}"
        logs: "{{ local_ip }}"
  roles:
    - { role: sysconf }
```

执行初始化安装

```bash
ansible-playbook -i inventory init.yml
```

## 单机安装
单机部署时，有两种方式
- hosts设置为 localhost（代表本机，ansible会做特殊处理），使用 ansible-playbook xxx.yml 命令安装
- 也可以按通用的方式 在inventory文件里指定机器，在xxx.yml里设置hosts为对应值，使用ansible-playbook -i inventory xxx.yml 命令安装
  单机安装文档是按照第一种方式描述的

### MySQL

#### 参数支持
可以在yml脚本里替换，会安装成指定值

| 描述      | 参数名称         | 默认值      |
| --------- | ---------------- | ----------- |
| admin账号 | mysql57_user     | root        |
| admin密码 | mysql57_password | 1qazzaq1    |
| 数据目录  | mysql57_datahome | /mysql_data |
| 端口      | mysql57_port     | 3306        |
| 安装目录  |software_install_path| /usr/local|

#### 按默认配置安装后的常用信息
用户和用户组：mysql
软件安装目录：/usr/local/mysql-5.7.28-linux-glibc2.12-x86_64/
数据目录：/mysql_data/3306/data/
配置文件位置：/mysql_data/3306/my.cnf
sock位置：/mysql_data/3306/mysql.sock
日志文件位置：/mysql_data/3306/  有mysql_3306_error.log、mysql-slow.log等日志

编辑 `mysql.yml` 文件（可以设置自定义参数值，其他组件类似）

```yml
- hosts: localhost
  remote_user: root
  vars:
    - mysql57_user: "root"
    - mysql57_password: "1qazzaq1"
    - mysql57_port: 3306
  roles:
    - { role: mysql }
```

#### 本机安装

```bash
ansible-playbook mysql.yml
```

#### 服务启停

| 描述     | 命令                     |
| -------- | ------------------------ |
| 启动     | service mysql3306 start  |
| 停止     | service mysql3306 stop   |
| 状态检查 | service mysql3306 status |

#### 验证

```bash
# 导入环境变量
source /etc/profile
# 可以正常进入mysql，如果没有mysql命令，需要重新登录root用户
mysql -u root -p --socket=/mysql_data/3306/mysql.sock
# sql语句可以正常使用
mysql> show databases;
```

### Java

#### 参数支持

| 描述      | 参数名称         | 默认值      |
| --------- | ---------------- | ----------- |
| 版本 只支持1.7或者1.8 | java_version   | 1.7        |
| 安装文件 只支持1.7或1.8 | java_file |   jdk-7u80-linux-x64.tar.gz  |
| java_home 会软链接到安装目录  | java_home | /usr/java/jdk1.7.0_80 |
| 安装目录  |software_install_path| /usr/local|

#### 按jdk18.yml配置安装后的常用信息

软件安装目录：/usr/local/jdk1.8.0_191
JAVA_HOME变量值：/usr/java/jdk1.8.0_191
设置JAVA_HOME的脚本位置：/etc/profile.d/java_home.sh

#### 本机安装

```bash
ansible-playbook jdk18.yml
```

#### 验证

```bash
#更新环境变量
source /etc/profile
# 验证java版本是否是指定版本1.8.0_191，如果已经登录了root，需要重新登录验证
java -version
```

### Tomcat

略，与应用程序一起提供打包安装

### Nginx

#### 参数支持

| 描述      | 参数名称         | 默认值      |
| --------- | ---------------- | ----------- |
| rpm包上传目录  |software_install_path| /usr/local|

#### 按默认配置安装后的常用信息

用户和用户组：nginx
软件安装目录：/usr/sbin/nginx
配置文件位置：/etc/nginx/nginx.conf
日志位置：/var/log/nginx  有access.log、error.log
pid文件位置：/var/run/nginx.pid
worker个数： 为cpu个数

#### 本机安装

```bash
ansible-playbook nginx.yml
```

#### 服务启停

| 描述     | 命令                 |
| -------- | -------------------- |
| 启动     | service nginx start  |
| 停止     | service nginx stop   |
| 状态检查 | service nginx status |

#### 验证

```bash
#查看nginx进程，有一个master、worker数量和cpu个数相同
ps -ef | grep nginx |grep -v grep
#看nginx状态
service nginx status
```

### Redis

#### 参数支持

| 描述         | 参数名称          | 默认值      |
| ------------ | ----------------- | ----------- |
| 密码         | redis_requirepass |             |
| 最大内存限制 | redis_maxmemory   | 1000mb      |
| 数据目录     | redis_datahome    | /redis_data |
| 端口         | redis_port        | 6379        |

#### 按默认配置安装后的常用信息
用户和用户组：redis
危险命令已禁用：KEYS、FLUSHALL、CONFIG、FLUSHDB
软件安装目录：/usr/local/redis-bin-4.0.12
软件安装目录软链接：/usr/local/redis
数据目录：/redis_data/6379/data/
配置文件位置：/redis_data/6379/redis.conf
日志文件位置：/redis_data/6379/redis-server.log

编辑 `redis.yml` 文件

```yml
- hosts: localhost
  remote_user: root
  vars:
    - redis_maxmemory: "1000mb"
    - redis_requirepass: "1qazzaq1"
    - redis_port: 6379
  roles:
    - { role: redis }
```


#### 本机安装

```bash
ansible-playbook redis.yml
```

#### 服务启停

| 描述     | 命令                     |
| -------- | ------------------------ |
| 启动     | service redis6379 start  |
| 停止     | service redis6379 stop   |
| 状态检查 | service redis6379 status |

#### 验证

```bash
# 看是否有redis服务
ps -ef | grep redis |grep -v grep
# 用客户端连接可以正常进入
/usr/local/redis/bin/redis-cli
# 用密码可以登录
127.0.0.1:6379> auth 1qazzaq1
# 用命令可以查询前100条
127.0.0.1:6379> set a 10
OK
127.0.0.1:6379> scan 0 count 100
1) "0"
2) 1) "a"
127.0.0.1:6379> quit
```

### Elasticsearch

#### 参数支持
| 描述         | 参数名称        | 默认值        |
| ------------ | --------------- | ------------- |
| 数据目录 | es_data_dirs | /opt/elasticsearch/data |
| 日志目录  |es_log_dir| /opt/elasticsearch/logs  |
| 最大使用内存     | es_heap_size  | 4g   |
| 端口         | http.port      | 9200          |

#### 按默认配置安装后的常用信息
用户和用户组：elasticsearch
安装目录：/usr/share/elasticsearch/
数据目录：/opt/elasticsearch/data
日志目录：/opt/elasticsearch/logs
配置文件位置：/etc/elasticsearch/node1/elasticsearch.yml

#### 本机安装

```bash
ansible-playbook es_685.yml
```

#### 服务启停

| 描述     | 命令                 |
| -------- | -------------------- |
| 启动     | service node1_elasticsearch start  |
| 停止     | service node1_elasticsearch stop   |
|状态检查	 | service node1_elasticsearch status |

#### 验证

```bash
# 查看elasticsearch是否启动
ps -ef | grep elasticsearch | grep -v grep
# 用命令查看机器状态是否是green 注意写机器IP
curl -XGET http://192.168.33.110:9200/_cat/health
# 结果示例
#1599652810 12:00:10 custom-cluster green 1 1 7 7 0 0 5 0 - 58.3%
```

### Kafka

#### 参数支持

| 描述         | 参数名称        | 默认值        |
| ------------ | --------------- | ------------- |
| kafka绑定的IP | local_ip | ansible_default_ipv4.address 最好明确指定|
| 安装目录  |software_install_path| /usr/local  |
| 数据目录     | kafka_datahome  | /kafka_data   |
| 端口         | kafka_port      | 9092          |
| jmx端口         | kafka_jmx_port      | 9192          |

#### 按默认配置安装后的常用信息
zookeeper用户和用户组：zookeeper
zookeeper安装目录：/usr/local/zookeeper-3.4.11
zookeeper数据目录：/zookeeper_data/2181/data/
zookeeper日志目录：/zookeeper_data/2181/logs/
zookeeper配置文件位置：/zookeeper_data/2181/zoo.cfg
kafka用户和用户组：kafka
kafka安装目录：/usr/local/kafka_2.11-0.10.0.0
kafka数据目录：/kafka_data/logs
kafka日志目录：/var/log/kafka/ 有controller.log、server.log等
kafka配置文件目录：/usr/local/kafka_2.11-0.10.0.0/config/server.properties

#### 本机安装

```bash
ansible-playbook kafka.yml
```

Kafka对外IP绑定在默认网卡上，多网卡情况下可以使用扩展参数手动指定绑定的IP对外提供服务

```bash
ansible-playbook kafka.yml --extra-vars "local_ip=本机IP"
```

#### 服务启停

| 描述     | 命令                 |
| -------- | -------------------- |
| 启动     | service kafka start  |
| 停止     | service kafka stop   |
|状态检查	 | service kafka status |

#### 验证

```bash
# 查看kafka和zookeeper是否启动
ps -ef | grep zookeeper | grep -v grep
# 用命令行创建topic成功
/usr/local/kafka/bin/kafka-topics.sh --create --zookeeper localhost:2181/kafka --replication-factor 1 --partitions 1 --topic test-topic
# 显示新创建的topic
/usr/local/kafka/bin/kafka-topics.sh --list --zookeeper localhost:2181/kafka
```

## 集群高可用方案

MySQL、Nginx、Redis的高可用都依赖于Keepalived，通过Keepalived监控中间件状态、切换vip的指向实现
Kafka的高可用依赖自身的机制

### Keepalived
MySQL、Nginx、Redis的高可用都隐含安装了Keepalived

#### 服务启停

| 描述     | 命令                 |
| -------- | -------------------- |
| 启动     | service keepalived start  |
| 停止     | service keepalived stop   |
|状态检查	 | service keepalived status |

#### Keepalived安装后的常用信息
Keepalived配置文件目录：/etc/keepalived/keepalived.conf
具体的配置文件在keepalived.conf里include进来，如：include scripts/keepalived-master-nginx.conf
具体中间件配置文件、检查脚本目录：/etc/keepalived/scripts/
例如：keepalived-master-nginx.conf、nginx_check.sh、nginx_stop.sh
配置文件里可以看到vip的配置、检查脚本的调用
查看Keepalived运行细节命令：journalctl -f

### MySQL 高可用：MySQL Master Master Keepalived

#### 高可用架构原理

案例IP

| 描述       | IP             |
| ---------- | -------------- |
| Master 主1 | 192.168.33.110 |
| Master 主2 | 192.168.33.111 |
| VIP        | 192.168.33.115 |

部署图

```bash
                            +----------+
                            |  uplink  |
                            +-----+----+
                                  |
                                  |
   MASTER                   keepalived vip              BACKUP
192.168.33.110              192.168.33.115            192.168.33.111
+------------+             +------+------+            +------------+
|   mysql    +-------------+ virtual vip +------------+   mysql    |
+------------+             +-------------+            +------------+
    MASTER                                               MASTER
```

#### 配置文件
修改  `inventory` 文件，增加2台机器的IP信息
```ini
[mysql1]
192.168.33.110
[mysql2]
192.168.33.111

[all:vars]
ansible_ssh_user=root        #
ansible_ssh_pass=vagrant     #root密码
```
修改  `mysql_ha.yml` 文件
```yml
---
#### 双机安装mysql
- hosts: mysql1,mysql2
  roles:
  - role: 'mysql'
    mysql57_port: '3306'
    mysql57_replication_role: 'master'
    mysql57_replication_user: {name: 'rep_3306', password: '123456'}
    
#### 配置第一台机器成为slave 192.168.33.110 --> 192.168.33.111
- hosts: mysql1
  roles:    
  - role: 'mysql'
    mysql57_port: '3306'
    mysql57_auto_increment_offset: '1'
    mysql57_auto_increment_increment: '2'
    mysql57_replication_role: 'slave' # 指定为slave角色
    mysql57_replication_master: '192.168.33.111'
    mysql57_replication_master_port: '3306'
    mysql57_replication_user: {name: 'rep_3306', password: '123456'}

#### 配置第二台机器成为slave 192.168.33.111 --> 192.168.33.110
- hosts: mysql2
  roles:
  - role: 'mysql'
    mysql57_port: '3306'
    mysql57_auto_increment_offset: '2'
    mysql57_auto_increment_increment: '2'
    mysql57_replication_role: 'slave'
    mysql57_replication_master: '192.168.33.110'
    mysql57_replication_master_port: '3306'
    mysql57_replication_user: {name: 'rep_3306', password: '123456'}

## 双机安装keepalived
- hosts: mysql1, mysql2
  remote_user: root
  vars:   
  roles:
    - keepalived

## 配置第一台机器keepalive-mysql，成为vip主节点，注意network_interface为vip所在网卡的网卡名称，默认一般是eth0或者eth1
- hosts: mysql1
  remote_user: root
  vars:
    - keepalived_role: "MASTER"
    - keepalived_vip: "192.168.33.115"
    - network_interface: "enp0s8" 
  roles:
    - keepalived-mysql

## 配置第二台机器keepalive-mysql，成为vip备节点，注意network_interface为vip所在网卡的网卡名称，默认一般是eth0或者eth1
- hosts: mysql2
  remote_user: root
  vars:
    - keepalived_role: "BACKUP"
    - keepalived_vip: "192.168.33.115"
    - network_interface: "enp0s8"
  roles:
    - keepalived-mysql
```
#### 安装脚本
```bash
ansible-playbook -i inventory mysql_ha.yml
```

#### 验证
```shell
# 验证mysql
#导入环境变量
source /etc/profile
# 在每台机器上检查是否安装成功，密码为1qazzaq1。没有mysql命令，需要重新登录。
mysql --host=127.0.0.1 --port=3306 --user=root -p --connect_timeout=3 -e "SELECT VERSION();" --socket=/mysql_data/3306/mysql.sock
Enter password:
+------------+
| version()  |
+------------+
| 5.7.28-log |
+------------+

# 检查配置，分别检查每台机器的同步状态Slave_IO_Running和Slave_SQL_Running都为Yes，则配置成功，否则检查Last_SQL_Errno和Last_SQL_Error
mysql --host=127.0.0.1 --port=3306 --user=root -p --connect_timeout=3 -e "SHOW SLAVE STATUS\G;" --socket=/mysql_data/3306/mysql.sock
*************************** 1. row ***************************
               Slave_IO_State: Waiting for master to send event
                  Master_Host: 192.168.33.111
                  Master_User: rep_3306
                  Master_Port: 3306
                          ......
             Slave_IO_Running: Yes
            Slave_SQL_Running: Yes
                          ......

# 验证高可用
# 验证keepalived状态
# 在两台机器上查看keepalived是否启动，有3个进程
ps -ef | grep keepalived | grep -v grep
# 在两台机器上查看vip，在其中一台机器可以看到vip，enp0s8是配置文件中对应的网卡
ip addr show dev enp0s8
# ping一下vip是否可达
ping 192.168.33.115
# 在一台停掉mysql
service mysql3306 stop
# 在外部访问vip 192.168.33.115看是否可用，注意3306端口要向外部开放
mysql --host=192.168.33.115 --port=3306 --user=root -p --connect_timeout=3 
# 启动这台机器，停掉另一台机器的mysql，再访问vip，看是否可用
# 两台都恢复状态，看是否可用
```

### Redis 高可用：Redis Master Slave Keepalived

#### 高可用架构原理

案例IP

| 描述       | IP             |
| ---------- | -------------- |
| Master 主1 | 192.168.33.110 |
| Slave  从2 | 192.168.33.111 |
| VIP        | 192.168.33.116 |

部署图

```bash
                            +----------+
                            |          |
                            |  uplink  |
                            |          |
                            +-----+----+
                                  |
                                  |
                                  |
                                  |
                                  |
   MASTER                   keepalived vip                BACKUP
192.168.33.110              192.168.33.116              192.168.33.111
+------------+             +------+------+            +------------+
|            |             |             |            |            |
|   redis    +-------------+ virtual vip +------------+   redis    |
|            |             |             |            |            |
+------------+             +-------------+            +------------+
    MASTER                                               SLAVE
```

#### 配置文件

修改  `inventory` 文件，增加2台机器的IP信息

```ini
[redis1]
192.168.33.110
[redis2]
192.168.33.111

[all:vars]
ansible_ssh_user=root        #
ansible_ssh_pass=vagrant     #root密码
```
修改 `redis_ha.yml` 文件
```yml
---
- hosts: redis1
  vars:
    - redis_requirepass: '123456'
    - redis_port: 6379
  roles:
    - { role: redis }

- hosts: redis2
  vars:
    - redis_master_host: "192.168.33.110"
    - redis_master_port: "6379"
    - redis_masterauth: '123456' 
    - redis_requirepass: '123456' 
    - redis_port: 6379
    - redis_slave: true
  roles:
    - { role: redis }

## 双机安装keepalived
- hosts: redis1, redis2
  vars:   
  roles:
    - keepalived

## 双机安装keepalived-redis
- hosts: redis1
  vars:
    - keepalived_role: "MASTER"
    - keepalived_vip: "192.168.33.116"
    - network_interface: "enp0s8"
    - redis_master_ip: '192.168.33.110'
    - redis_master_port: 6379
    - redis_slave_ip: '192.168.33.111'
    - redis_slave_port: 6379
    - redis_requirepass: '123456'
  roles:
    - keepalived-redis

- hosts: redis2
  vars:
    - keepalived_role: "BACKUP"
    - keepalived_vip: "192.168.33.116"
    - network_interface: "enp0s8"
    - redis_master_ip: '192.168.33.110'
    - redis_master_port: 6379
    - redis_slave_ip: '192.168.33.111'
    - redis_slave_port: 6379
    - redis_requirepass: '123456'
  roles:
    - keepalived-redis
```

#### 安装脚本

```bash
ansible-playbook -i inventory redis_ha.yml
```

#### 验证

```bash
# 验证keepalived状态
# 在两台机器上查看keepalived是否启动，有3个进程
ps -ef | grep keepalived |grep -v grep
# 在两台机器上查看vip，在其中一台机器可以看到vip，enp0s8是配置文件中对应的网卡
ip addr show dev enp0s8
# ping一下vip是否可达
ping 192.168.33.116

#验证主从数据是否能同步
# 在master 192.168.33.110上设置值
/usr/local/redis/bin/redis-cli
127.0.0.1:6379> auth 123456
127.0.0.1:6379> set a a
OK
# 在slave 192.168.33.111上看是否已同步
/usr/local/redis/bin/redis-cli
127.0.0.1:6379> auth 123456
127.0.0.1:6379> scan 0 match a count 10
1) "0"
2) 1) "a"
# 在master上删除键
127.0.0.1:6379> del a
(integer)1
# 看slave是否同步
127.0.0.1:6379> scan 0 match a count 10
1) "0"
2) (empty list or set)

#验证高可用
# 在master关掉redis
service redis6379 stop
# 验证高可用，在外部使用vip访问redis依然可用，可以用外部的程序或者命令行验证。如果用命令行，能进去即可
redis-cli -h 192.168.33.116 -p 6379
# 在master启动redis，在slave关掉redis，验证可用性
service redis6379 start
# 都恢复，验证可用性，再验证可用性
```

### Elasticsearch 高可用：Elasticsearch Cluster

#### 高可用架构原理

案例IP

| 描述       | IP             |
| ---------- | -------------- |
| node1 | 192.168.33.110 |
| node2 | 192.168.33.111 |
| node3 | 192.168.33.112 |

部署图

```bash

            node1                 node2                node3
        192.168.33.110       192.168.33.111       192.168.33.112
        +-------------+      +-------------+      +-------------+
        |elasticsearch|      |elasticsearch|      |elasticsearch|
        +-------------+      +-------------+      +-------------+

```

#### 配置文件

修改 `inventory` 文件，指定安装es集群的IP
```ini
[node1]
192.168.33.110
[node2]
192.168.33.111
[node3]
192.168.33.112
```

修改  ` es_685_ha.yml ` 文件配置示例如下，es_heap_size指定最大内存，network.host配置当前机器的IP，和discovery.zen.ping.unicast.hosts配置机器所有机器的IP
```yml
---
- hosts: node1
  remote_user: root
  vars:
    - java_version: "1.8"
    - java_home: "/usr/java/jdk1.8.0_191"
    - java_file: "jdk-8u191-linux-x64.tar.gz"
    - java_install_path: "{{ software_install_path }}/jdk1.8.0_191"
  roles:
    - { role: java }

- name: Elasticsearch with custom configuration
  hosts: node1
  roles:
    - role: elasticsearch
  vars:
    es_instance_name: "node1"
    es_data_dirs:
      - "/opt/elasticsearch/data"
    es_log_dir: "/opt/elasticsearch/logs"
    es_config:
      node.name: "node1"
      cluster.name: "es_cluster"
      network.host: "192.168.33.110, _local_"
      discovery.zen.ping.unicast.hosts: "192.168.33.110, 192.168.33.111, 192.168.33.112"
      node.master: true
      node.data: true
      discovery.zen.minimum_master_nodes: 2           # 配置最少节点数量，防止脑裂
      bootstrap.memory_lock: true
      http.cors.enabled: true
      http.cors.allow-origin: "*"
      http.cors.allow-methods: OPTIONS, HEAD, GET, POST, PUT, DELETE
      http.cors.allow-headers: "X-Requested-With,X-Auth-Token,Content-Type, Content-Length, Authorization"
    es_use_repository: false
    es_enable_xpack: false
    es_scripts: false
    es_templates: false
    es_version_lock: false
    es_heap_size: 4g
    es_api_port: 9200
    es_major_version: "6.x"
    es_version: "6.8.5"

- hosts: node2
  remote_user: root
  vars:
    - java_version: "1.8"
    - java_home: "/usr/java/jdk1.8.0_191"
    - java_file: "jdk-8u191-linux-x64.tar.gz"
    - java_install_path: "{{ software_install_path }}/jdk1.8.0_191"
  roles:
    - { role: java }

- name: Elasticsearch with custom configuration
  hosts: node2
  roles:
    - role: elasticsearch
  vars:
    es_instance_name: "node2"
    es_data_dirs:
      - "/opt/elasticsearch/data"
    es_log_dir: "/opt/elasticsearch/logs"
    es_config:
      node.name: "node2"
      cluster.name: "es_cluster"
      network.host: "192.168.33.111, _local_"
      discovery.zen.ping.unicast.hosts: "192.168.33.110, 192.168.33.111, 192.168.33.112"
      node.master: true
      node.data: true
      discovery.zen.minimum_master_nodes: 2           # 配置最少节点数量，防止脑裂
      bootstrap.memory_lock: true
      http.cors.enabled: true
      http.cors.allow-origin: "*"
      http.cors.allow-methods: OPTIONS, HEAD, GET, POST, PUT, DELETE
      http.cors.allow-headers: "X-Requested-With,X-Auth-Token,Content-Type, Content-Length, Authorization"
    es_use_repository: false
    es_enable_xpack: false
    es_scripts: false
    es_templates: false
    es_version_lock: false
    es_heap_size: 4g
    es_api_port: 9200
    es_major_version: "6.x"
    es_version: "6.8.5"

- hosts: node3
  remote_user: root
  vars:
    - java_version: "1.8"
    - java_home: "/usr/java/jdk1.8.0_191"
    - java_file: "jdk-8u191-linux-x64.tar.gz"
    - java_install_path: "{{ software_install_path }}/jdk1.8.0_191"
  roles:
    - { role: java }

- name: Elasticsearch with custom configuration
  hosts: node3
  roles:
    - role: elasticsearch
  vars:
    es_instance_name: "node3"
    es_data_dirs:
      - "/opt/elasticsearch/data"
    es_log_dir: "/opt/elasticsearch/logs"
    es_config:
      node.name: "node3"
      cluster.name: "es_cluster"
      network.host: "192.168.33.112, _local_"
      discovery.zen.ping.unicast.hosts: "192.168.33.110, 192.168.33.111, 192.168.33.112"
      node.master: true
      node.data: true
      discovery.zen.minimum_master_nodes: 2           # 配置最少节点数量，防止脑裂
      bootstrap.memory_lock: true
      http.cors.enabled: true
      http.cors.allow-origin: "*"
      http.cors.allow-methods: OPTIONS, HEAD, GET, POST, PUT, DELETE
      http.cors.allow-headers: "X-Requested-With,X-Auth-Token,Content-Type, Content-Length, Authorization"
    es_use_repository: false
    es_enable_xpack: false
    es_scripts: false
    es_templates: false
    es_version_lock: false
    es_heap_size: 4g
    es_api_port: 9200
    es_major_version: "6.x"
    es_version: "6.8.5"

```

#### 安装脚本

```bash
ansible-playbook -i inventory es_685_ha.yml
```

#### 验证

```bash
#在3台机器看elasticsearch进程是否起来
ps -ef | grep elasticsearch |grep -v grep
#在某台机器如192.168.33.110，用命令查看集群状态是否green
curl -XGET http://192.168.33.110:9200/_cat/health
```

### Kafka 高可用：Kafka Cluster

#### 高可用架构原理

案例IP

| 描述       | IP             |
| ---------- | -------------- |
| broker1 | 192.168.33.110 |
| broker2 | 192.168.33.111 |
| broker3 | 192.168.33.112 |

部署图

```bash

            broker1             broker2              broker3
         192.168.33.110      192.168.33.111       192.168.33.112
          +---------+         +---------+          +---------+
          |zookeeper|         |zookeeper|          |zookeeper|
          |kafka    |         |kafka    |          |kafka    |
          +---------+         +---------+          +---------+

```

#### 配置文件

修改 `inventory` 文件注意每台机器分配不同的kafka_id, kafka_ip配置本机对外提供服务ip即可（解决多网卡时无法找到默认ip）
```ini
[kafka]
192.168.33.110 kafka_id=1 kafka_ip="192.168.33.110"
192.168.33.111 kafka_id=2 kafka_ip="192.168.33.111"
192.168.33.112 kafka_id=3 kafka_ip="192.168.33.112"
```

修改  ` kafka_cluster.yml ` 文件配置示例如下，zookeeper每台id需要不同；zookeeper_auth_ips是能访问zookeeper的IP列表，需要把所有要访问zookeeper的IP加入（127.0.0.1必须加），否则会报权限错误
```yml
---
- hosts: kafka
  remote_user: root
  vars:
   - kafka_zk_quorum: 192.168.33.110:2181,192.168.33.111:2181,192.168.33.112:2181/kafka
   - zookeeper_hosts:
      - {'host': 192.168.33.110, 'id': 1, 'port': 2181, 'leader_port': '2888:3888'}
      - {'host': 192.168.33.111, 'id': 2, 'port': 2181, 'leader_port': '2888:3888'}
      - {'host': 192.168.33.112, 'id': 3, 'port': 2181, 'leader_port': '2888:3888'}
   - zookeeper_auth_ips:
      - 127.0.0.1
      - 192.168.33.110
      - 192.168.33.111
      - 192.168.33.112
  roles:
    - { role: java }
    - { role: zookeeper }
    - { role: kafka }
```

#### 安装脚本

```bash
ansible-playbook -i inventory kafka_cluster.yml
```

#### 验证

```bash
#在3台机器看zookeeper、kafka进程是否起来
ps -ef | grep zookeeper |grep -v grep
#在某台机器上创建topic验证
/usr/local/kafka/bin/kafka-topics.sh --create --zookeeper 192.168.33.110:2181,192.168.33.111:2181,192.168.33.112:2181/kafka --replication-factor 1 --partitions 1 --topic test-topic
#查看topic验证
/usr/local/kafka/bin/kafka-topics.sh --list --zookeeper 192.168.33.110:2181,192.168.33.111:2181,192.168.33.112:2181/kafka
```

### Nginx 高可用：Nginx + Keepalived
#### 高可用架构原理

案例IP

| 描述       | IP             |
| ---------- | -------------- |
| Master 主1 | 192.168.33.110 |
| Slave  从2 | 192.168.33.111 |
| VIP        | 192.168.33.117 |

部署图

```bash
                            +----------+
                            |          |
                            |  uplink  |
                            |          |
                            +-----+----+
                                  |
                                  |
                                  |
                                  |
                                  |
   MASTER                   keepalived vip                BACKUP
192.168.33.110              192.168.33.117              192.168.33.111
+------------+             +------+------+            +------------+
|            |             |             |            |            |
|   Nginx    +-------------+ virtual vip +------------+   Nginx    |
|            |             |             |            |            |
+------------+             +-------------+            +------------+
    MASTER                                               SLAVE
```

#### 配置文件

修改  `inventory` 文件，增加2台机器的IP信息

```ini
[nginx1]
192.168.33.110
[nginx2]
192.168.33.111

[all:vars]
ansible_ssh_user=root        #
ansible_ssh_pass=vagrant     #root密码
```
修改 `nginx_ha.yml` 文件
```yml
---
## 双机安装 Nginx
- hosts: nginx1, nginx2
  roles:
    - { role: nginx }

## 双机安装 Keepalived
- hosts: nginx1, nginx2
  vars:
  roles:
    - keepalived

## 双机配置 Keepalived-nginx
- hosts: nginx1
  vars:
    - keepalived_role: "MASTER"
    - keepalived_vip: "192.168.33.117"    #修改为VIP地址
    - network_interface: "enp0s8"         #修改为IP所在网卡名
  roles:
    - keepalived-nginx

- hosts: nginx2
  vars:
    - keepalived_role: "BACKUP"
    - keepalived_vip: "192.168.33.117"    #修改为VIP地址
    - network_interface: "enp0s8"         #修改为IP所在网卡名
  roles:
    - keepalived-nginx
```

#### 安装脚本

```bash
ansible-playbook -i inventory nginx_ha.yml
```

#### 验证

```bash
# 验证keepalived状态
# 在两台机器上查看keepalived是否启动，有3个进程
ps -ef | grep keepalived | grep -v grep
# 在两台机器上查看vip，都可以看到vip，enp0s8是配置文件中对应的网卡
ip addr show dev enp0s8
# ping一下vip是否可达
ping 192.168.33.117

#在各台机器查看nginx进程，有一个master、worker数量和cpu个数相同
ps -ef | grep nginx | grep -v grep
root       864     1  0 06:02 ?        00:00:00 nginx: master process /usr/sbin/nginx -c /etc/nginx/nginx.conf
nginx      865   864  0 06:02 ?        00:00:00 nginx: worker process

#验证高可用
# 在master关掉nginx
service nginx stop
# 验证高可用，在外部使用vip访问nginx依然可用，调到404页面是正确的
curl http://192.168.33.117:80
# 在master启动nginx，在slave关掉nginx，验证可用性
service nginx start
# 都恢复，验证可用性，再验证可用性
```

### 多个高可用中间件部署在相同机器

多个高可用中间件可以部署在相同的机器，如在两台机器上部署 Nginx + Redis + Keepalived

部署在相同机器时，要各自分配单独的vip、router_id、instance。例如：两台机器同时部署了nginx和redis高可用，要给他们分配不同的vip、router_id、instance。否则会互相影响，破坏高可用。

#### 高可用架构原理

案例IP

| 描述       | IP             |
| ---------- | -------------- |
| Master 主1 | 192.168.33.110 |
| Slave  从2 | 192.168.33.111 |
| VIP1 nginx | 192.168.33.117 |
| VIP2 redis | 192.168.33.116 |

部署图

```bash
                            +----------+
                            |          |
                            |  uplink  |
                            |          |
                            +-----+----+
                                  |
                                  |
                                  |
                                  |
                                  |
   MASTER                   keepalived vip                BACKUP
192.168.33.110              192.168.33.117              192.168.33.111
+------------+             +------+------+            +------------+
|            |             |             |            |            |
|   Nginx    +-------------+ virtual vip +------------+   Nginx    |
|            |             |             |            |            |
+------------+             +-------------+            +------------+
    MASTER                                               SLAVE


   MASTER                   keepalived vip                BACKUP
192.168.33.110              192.168.33.116              192.168.33.111
+------------+             +------+------+            +------------+
|            |             |             |            |            |
|   redis    +-------------+ virtual vip +------------+   redis    |
|            |             |             |            |            |
+------------+             +-------------+            +------------+
    MASTER                                               SLAVE
```

#### 配置文件

修改  `inventory` 文件，增加2台机器的IP信息

```ini
[nginx1]
192.168.33.110
[nginx2]
192.168.33.111

[all:vars]
ansible_ssh_user=root        #
ansible_ssh_pass=vagrant     #root密码
```

修改 `multi_ha.yml` 文件

在两台机器上都安装nginx、redis、keepalived，并配置nginx高可用和redis高可用，安装其他高可用配置类似。
```yml
---
## 双机安装 Nginx
- hosts: nginx1, nginx2
  roles:
    - { role: nginx }

## 双机安装redis
- hosts: nginx1
  vars:
    - redis_requirepass: '123456'
    - redis_port: 6379
  roles:
    - { role: sysconf }  
    - { role: redis }

- hosts: nginx2
  vars:
    - redis_master_host: "192.168.33.110"
    - redis_master_port: "6379"
    - redis_masterauth: '123456' 
    - redis_requirepass: '123456' 
    - redis_port: 6379
    - redis_slave: true
  roles:
    - { role: sysconf }
    - { role: redis }

## 双机安装 Keepalived
- hosts: nginx1, nginx2
  vars:
  roles:
    - keepalived

## 双机配置 Keepalived-nginx
- hosts: nginx1
  vars:
    - virtual_router_id: 50
    - keepalived_role: "MASTER"
    - keepalived_vip: "192.168.33.117"    #修改为VIP地址
    - network_interface: "enp0s8"         #修改为IP所在网卡名
  roles:
    - keepalived-nginx

- hosts: nginx2
  vars:
    - virtual_router_id: 50
    - keepalived_role: "BACKUP"
    - keepalived_vip: "192.168.33.117"    #修改为VIP地址
    - network_interface: "enp0s8"         #修改为IP所在网卡名
  roles:
    - keepalived-nginx

## 双机安装keepalived-redis
- hosts: nginx1
  vars:
    - virtual_router_id: 51
    - keepalived_role: "MASTER"
    - keepalived_vip: "192.168.33.116"
    - network_interface: "enp0s8"
    - redis_master_ip: '192.168.33.110'
    - redis_master_port: 6379
    - redis_slave_ip: '192.168.33.111'
    - redis_slave_port: 6379
    - redis_requirepass: '123456'
  roles:
    - keepalived-redis

- hosts: nginx2
  vars:
    - virtual_router_id: 51
    - keepalived_role: "BACKUP"
    - keepalived_vip: "192.168.33.116"
    - network_interface: "enp0s8"
    - redis_master_ip: '192.168.33.110'
    - redis_master_port: 6379
    - redis_slave_ip: '192.168.33.111'
    - redis_slave_port: 6379
    - redis_requirepass: '123456'
  roles:
    - keepalived-redis

```

#### 安装脚本

```bash
ansible-playbook -i inventory multi_ha.yml
```

#### 验证

按前述文档分别验证nginx和redis高可用即可。

## 各中间件关键参数配置说明
解释中间件的关键配置项。

### MySQL
配置sock文件路径，表名不区分大小写，服务器字符集，慢sql记录。
```ini
[client]
# sock文件路径
socket          = /mysql_data/3306/mysql.sock

# 表名不区分大小写
######server####################
lower_case_table_names = 1

# 服务器字符集
######character####################
character-set-server = utf8mb4

# 慢sql记录
######slow log##################
slow-query-log = on
slow_query_log_file = /mysql_data/3306/mysql-slow.log
long_query_time = 2
```

### Redis
配置最大使用内存，设置密码，禁用敏感命令。
```ini
# 设置密码
requirepass 123456

# 设置最大使用内存
maxmemory 1000mb

# 禁用敏感命令
rename-command KEYS     "BJCA_KEYS"
rename-command CONFIG   "BJCA_CONFIG"
rename-command FLUSHALL "BJCA_FLUSHALL"
rename-command FLUSHDB  "BJCA_FLUSHDB"
```

### Nginx
只有基础配置，根据cpu数设置worker数量。
```ini
# 根据cpu数配置
worker_processes 1;
```

### Zookeeper
需要注意配置自动清理数据，防止占满磁盘。
```ini
# Purge task interval in hours
# Set to "0" to disable auto purge feature
autopurge.purgeInterval=24
# The number of snapshots to retain in dataDir
autopurge.snapRetainCount=20
```

### Kafka
需要明确指定IP、数据保存时长和大小、zookeeper路径。
```ini
############################# Socket Server Settings #############################
# IP需要明确指定为本机IP，端口可以自定义
port=9092
listeners=PLAINTEXT://192.168.50.222:9092

############################# Log Basics #############################
# 数据存储位置
log.dirs=/kafka_data/logs

############################# Log Retention Policy #############################
# 数据保存168小时
log.retention.hours=168
# 日志文件最大1G
log.segment.bytes=1073741824
# 每隔300秒清理一次
log.retention.check.interval.ms=300000

############################# Zookeeper #############################
# 指定zookeeper路径，防止和其他使用zookeeper的应用冲突
zookeeper.connect=localhost:2181/kafka
```

### Keepalived
具体配置都在主配置文件/etc/keepalived/keepalived.conf里用include包含。
```ini
include scripts/keepalived-master-nginx.conf
```
具体配置文件中，要注意instance、网卡、router_id的配置。
```ini
# 多套中间件，比如同时安装了mysql、redis高可用，它们各自的vrrp_instance不能相同
vrrp_instance rk {
    ......
    # 虚IP要绑定到哪个网卡上
    interface eth1
    # 多套中间件，比如同时安装了mysql、redis高可用，它们各自的virtual_router_id不能相同
    virtual_router_id 54
    ......
    # 虚IP地址
    virtual_ipaddress {
        192.168.1.13
    }
```

## FAQ
公司WIKI会实时更新最新问题，不断完善，请关注 http://192.168.131.51:8090/pages/viewpage.action?pageId=31687030

### 一键部署只能在新的干净环境安装
如果目标机已有非一键部署安装的mysql、ansible等程序，需要先卸载干净

### 一键部署需要在每台机器上都安装ansible吗
不需要，只要在一台机器上安装ansible执行命令，都在这台机器上操作即可
要安装中间件的多个目标机，在配置文件inventory里设置

### 不要在openstack机器测试中间件安装
kafka、elasticsearch等中间件需要绑定机器ip，openstack环境绑不上真实ip，最好用虚拟机测试。

###  MySQL Redis Kafka 重装前要手动清数据
因为可能已有业务数据，不能自动删除，防止误删。要手动操作。
```bash
# MySQL
rm -rf /mysql_data
# Redis
rm -rf /redis_data
# Kafka
rm -rf /zookeeper_data  
rm -rf /kafka_data
```
### MySQL安装报 can't create/write to file /tmp/ib6cnet0
由于root用户对 /tmp文件夹没权限导致
或者用  getenforce 看一下selinux关掉没，需要关掉
解决办法：chmod 777 /tmp
再删掉mysql数据 rm -rf /mysql_data，重新执行脚本

### 高可用安装不正确或外部访问不到服务
网络需要都打通，测试是在防火墙关闭的情况下做的。

### 安装中间件后没有对应命令
导入环境变量，或退出后重新登录系统
```bash
source /etc/profile
```

### mysql高可用安装报错
Fatal error: The slave I/O thread stops because master and slave have equal MySQL server ids
一台机器需要配置为另一台机器的slave，IP不能配成相同的。如：mysql1的ip是192.168.33.110，配置要写192.168.33.111
```yml
#### 配置第一台机器成为slave 192.168.33.110 --> 192.168.33.111
- hosts: mysql1
  roles:    
  - role: 'mysql'
    mysql57_port: '3306'
    mysql57_auto_increment_offset: '1'
    mysql57_auto_increment_increment: '2'
    mysql57_replication_role: 'slave' # 指定为slave角色
    mysql57_replication_master: '192.168.33.111'
    mysql57_replication_master_port: '3306'
    mysql57_replication_user: {name: 'rep_3306', password: '123456'}
```

### mysql高可用装错后，再装报错
由于业务数据很重要，程序不应该也不能自动清理，需手动清理后再安装。
到两台机器执行清理 systemctl stop mysql3306.service && rm -rf /mysql_data/

### redis安装报错
#### error: "net.bridge.bridge-nf-call-ip6tables" is an unknown key
系统没有安装好，系统装完后需/sbin/sysctl -p 不报错再安装程序
解决方式： vi /etc/sysctl.conf 把报错删掉，/sbin/sysctl -p 无错误后再装
或者modprobe bridge 启动bridge模块
#### 执行到 vm.overcommit_memory to 1 报错
由于 redis.yml 脚本里 redis_maxmemeory的设置大于目标机可用内存
解决方式：free -m看一下目标机还剩多少可用内存，设置内存不要大于可用内存
#### 执行unarchive任务报错
直接到目录下解压压缩文件，看会不会报错，如果报错，就是要解压的文件损坏了  解决办法：上传一份完整的文件
或者目标机没有安装tar、unzip命令  解决办法：安装对应命令

#### 高可用的 VIP 和 端口 访问不到
在客户现场，可能有网络限制，需要找客户开通VIP的网络和端口权限才行

### nginx安装了哪些模块
nginx version: nginx/1.16.1
built by gcc 4.8.5 20150623 (Red Hat 4.8.5-36) (GCC)
built with OpenSSL 1.0.2k-fips  26 Jan 2017
TLS SNI support enabled
configure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib64/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -fPIC' --with-ld-opt='-Wl,-z,relro -Wl,-z,now -pie'

### 如何不用root用户执行脚本，实现部署任务
案例：客户的环境禁用root用户。但是提供了一个user用户，密码是123456，并且user账户可通过sudo su 方式提权使用root权限。
解决方式：修改inventory文件，目标机添加如下参数，正常执行ansible-playbook -i inventory xxx.yml即可：
```ini
[mysql]
192.168.33.21 ansible_ssh_user=user ansible_ssh_pass='123456' ansible_become=true ansible_become_user=root ansible_become_pass='123456'
```

### 目标机端口不是默认的22怎么办
在inventory文件里加上指定端口
```ini
[all:vars]
ansible_ssh_user=root
ansible_ssh_pass=vagrant
ansible_ssh_port=65535
```

### 整个包太大了，能只上传要安装的包吗？
可以，解压出库的包，把根目录下文件都上传（注意，根目录下的文件都要上传，并且sysconf目录也必须上传），只上传需要的文件夹。按文档执行命令即可。
比如单机安装mysql，只上传mysql文件夹即可。
|要安装的组件|需要上传的目录|
|-----------|-------------|
|单机mysql	|mysql|
|高可用mysql|	mysql、keepalived、keepalived-mysql|
|单机nginx	|nginx|
|高可用nginx|	nginx、keepalived、keepalived-nginx|
|单机redis|redis|
|高可用redis	|redis、keepalived、keepalived-redis|
|单机kafka<br>高可用kafka|java、zookeeper、kafka|
|单机elasticsearch<br>高可用elasticsearch|java、elasticsearch|
